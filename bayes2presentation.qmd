---
title: |
  Evaluation of Partial Measurement Invariance<br>
  Under Sparse Ordinal Indicators 
subtitle: "Using Induced Dirichlet Threshold Priors"
author:
  - name: Fatih Ozkan & Jianwen Song
    affiliation: |
      - name: Baylor University
        department: Educational Psychology
        url: https://www.baylor.edu
date: today
date-format: "MMMM D, YYYY"
format:
  revealjs:
    include-in-header:
      - _macros.tex
      - text: |
          <link rel="stylesheet" href="custom-styles.css">
    theme:
       - baylor-theme.scss
    smaller: true
    scrollable: false
    show-slide-number: all
    toc: false
    toc-depth: 1
    preview-links: true
    slide-number: c/t
    multiplex: true
    embed-resources: true
    auto-animate: true
    footer: "Fatih Ozkan & Jianwen Song"
bibliography: references.bibtex
lightbox:
  match: auto
  effect: fade
  desc-position: bottom
  loop: true
logo: "baylor.png"
license: "CC BY-NC"
copyright:
  holder: Fatih Ozkan & Jianwen Song
  year: 2025
editor:
  markdown:
    wrap: 72
---

------------------------------------------------------------------------

```{r, setup}
#| include: false
#| message: false
library(knitr)
library(tidyverse)
library(conflicted)
library(janitor)
library(ggtda)
# library(TDAvis)
library(patchwork)
library(gganimate)
library(ggforce)
library(simplextree) 
library(gifski)
library(magick)  
library(ripserr)
library(BayesTDA)
library(TDAstats)
library(mvtnorm)
library(kableExtra)
library(plotly)
conflicted::conflict_prefer("filter", "dplyr")
conflicted::conflict_prefer("select", "dplyr")
conflicted::conflicts_prefer(ggtda::geom_simplicial_complex)
conflicted::conflicts_prefer(plotly::layout)
knitr::opts_chunk$set(
  comment = "#>",
  message = FALSE,
  warning = FALSE,
  cache = TRUE,
  echo = FALSE,
  tidy.opts = list(width.cutoff = 100),
  tidy = FALSE,
  fig.align = "center"
)
ggplot2::theme_set(ggplot2::theme_minimal())
ggplot2::theme_update(panel.grid.minor = ggplot2::element_blank())

#------------------------------------------------------------#
```

# Contents

1.  [Introduction](#sec-intro)
2.  [Study Aims and Rationale](#sec-background)
3.  [Bayesian Framework](#sec-bayes)
4.  [Worked Example](#sec-example)
5.  [References](#sec-bib)

# Introduction {#sec-intro}

-   This research builds directly on Padgett et al. (2024), who proposed
    an induced-Dirichlet prior for threshold parameters in Bayesian SEM
    to address sparse response patterns in ordinal indicators.
-   While Padgett and colleagues demonstrated the improved
    regularization and sampling efficiency of this approach, our study
    extends their work by applying the induced-Dirichlet threshold prior
    within a multi-group Bayesian factor analysis framework to evaluate
    partial measurement invariance without collapsing categories under
    varying conditions of sparsity.

## Intro cont.

::: incremental
-   Motivation

    -   Many educational and psychological assessments rely on ordinal
        survey items administered across diverse groups, where ensuring
        comparability of latent constructs is essential.

    -   Sparse responses in less-endorsed categories (e.g., extreme
        options) lead to unstable parameter estimates and biased
        invariance testing.

-   Current methods for addressing sparse ordinal data in invariance
    testing

    -   Frequentist approaches often collapse rare categories or remove
        problematic items, sacrificing information and statistical
        power.

    <!-- -->

    -   Bayesian models with sequential normal priors can struggle with
        convergence and inflated uncertainty when data are highly
        sparse.

    -   Existing ad-hoc fixes lack principled priors to regularize
        threshold estimation under sparse conditions.\
:::

## A Prior‐draw Diagnostic for the Induced‐Dirichlet Threshold Prior

```{r bcc}
# Install and load packages
grep <- function(x) { invisible() } # placeholder
if (!requireNamespace("gtools", quietly=TRUE)) install.packages("gtools")
if (!requireNamespace("plotly", quietly=TRUE)) install.packages("plotly")
if (!requireNamespace("ggtern", quietly=TRUE)) install.packages("ggtern")
library(gtools)
library(plotly)
library(ggtern)

# Set seed and parameters
set.seed(123)
n_draws <- 5000  # number of samples
K <- 4            # number of categories

# Draw probabilities from Dirichlet(alpha = 1 for each category)
# Explicitly call gtools::rdirichlet to resolve namespace conflict
probs <- gtools::rdirichlet(n_draws, rep(1, K))
colnames(probs) <- paste0("p", 1:K)

# Convert to thresholds via inverse-normal CDF (drop the last category)
taus <- t(apply(probs[, 1:(K - 1)], 1, function(p) qnorm(cumsum(p))))
colnames(taus) <- paste0("tau", 1:(K - 1))
data3d <- as.data.frame(taus)

# 3D scatter of threshold draws
plot_ly(
  data3d,
  x = ~tau1, y = ~tau2, z = ~tau3,
  type = 'scatter3d', mode = 'markers',
  marker = list(size = 2, opacity = 0.5)
) %>%
  layout(
    title = '3D Scatter of Threshold Draws',
    scene = list(
      xaxis = list(title = expression(tau[1])),
      yaxis = list(title = expression(tau[2])),
      zaxis = list(title = expression(tau[3]))
    )
  )

# 2D ternary plot of the first three Dirichlet probabilities
# Prepare data for ternary
data_tern <- as.data.frame(probs[, 1:3])
colnames(data_tern) <- c("p1", "p2", "p3")

# Build ternary plot using ggtern and ggplot2 geoms
tern_plot <- ggtern::ggtern(
  data = data_tern,
  mapping = ggtern::aes(x = p1, y = p2, z = p3)
) +
  ggplot2::geom_point(size = 1, alpha = 0.5) +
  ggplot2::labs(
    title = 'Ternary Plot of Dirichlet Probabilities',
    T = 'p1', L = 'p2', R = 'p3'
  ) +
  ggplot2::theme_bw()


```

## 3D Prior Densities of Ordered Thresholds under Varying Dirichlet Concentrations

```{r fcc}
# Complete R Script: 3D Density Plots of τ₁, τ₂, τ₃ for Five α Settings

# 1) Install / load packages
if (!requireNamespace("gtools", quietly=TRUE)) install.packages("gtools")
if (!requireNamespace("plotly", quietly=TRUE)) install.packages("plotly")

library(gtools)    # for rdirichlet
library(plotly)    # for 3D plotting

# 2) Define α settings
alpha_list <- list(
  "1,1,1,1"     = c(1,  1,  1,  1),
  "10,50,50,10" = c(10, 50, 50, 10),
  "10,10,10,10" = c(10, 10, 10, 10),
  "1,2,2,1"     = c(1,  2,  2,  1),
  "2,1,1,2"     = c(2,  1,  1,  2)
)

set.seed(2025)
n_draws <- 30000

# 3) Sample and compute thresholds + densities
all_plots <- lapply(names(alpha_list), function(lbl) {
  α   <- alpha_list[[lbl]]
  # draw Dirichlet probabilities
  probs <- gtools::rdirichlet(n_draws, α)
  # convert first 3 cumulative probabilities to taus
  taus <- t(apply(probs[,1:3], 1, function(p) qnorm(cumsum(p))))
  df   <- data.frame(taus)
  names(df) <- c("tau1","tau2","tau3")
  
  # compute densities for each tau
  dens_df <- do.call(rbind, lapply(1:3, function(i) {
    d <- density(df[[i]])
    data.frame(
      threshold    = paste0("τ", i),
      value        = d$x,
      density      = d$y
    )
  }))
  
  # create 3D density plot for this α
  p <- plot_ly(
    dens_df,
    x     = ~threshold,
    y     = ~value,
    z     = ~density,
    color = ~threshold,
    colors = c("τ1"="red","τ2"="darkgray","τ3"="blue"),
    type  = "scatter3d",
    mode  = "lines",
    line  = list(width = 3)
  ) %>%
    layout(
      title = paste0("3D Density under Induced-Dirichlet(", lbl, ")"),
      scene = list(
        xaxis = list(title = "Threshold"),
        yaxis = list(title = "τ value"),
        zaxis = list(title = "Density")
      ),
      legend = list(title=list(text="Threshold"))
    )
  p
})

# 4) Arrange into a 2×3 grid (last cell empty)
subplot(
  all_plots, 
  nrows    = 2, 
  margin   = 0.02, 
  shareY   = FALSE, 
  shareX   = FALSE
) %>%
  layout(title = "3D Densities of τ₁, τ₂, τ₃ for Various α Settings")
```

## Real World Problem: Face Centered Cubic2

```{r fcc_fig6_3d}
library(gtools)
library(plotly)

# 2) Generate made-up data
set.seed(2025)
n_draws <- 5000

# Prior draws for τ₁
prior_list <- list(
  A = qnorm(gtools::rdirichlet(n_draws, c(1,1,1,1))[,1]),
  B = qnorm(gtools::rdirichlet(n_draws, c(1,3,8,4))[,1]),
  C = rnorm(n_draws, 0, 1.5),
  D = rnorm(n_draws, 0, 1e5)
)

# Posterior draws (made-up)
us_draws <- list(
  A = rnorm(n_draws, -0.5, 0.5),
  B = rnorm(n_draws, -1.2, 0.4),
  C = rnorm(n_draws, 0.2,  1.5),
  D = rnorm(n_draws, -0.1, 1.0)
)
no_draws <- list(
  A = rnorm(n_draws, -1.0, 0.5),
  B = rnorm(n_draws, -1.8, 0.6),
  C = rnorm(n_draws, -0.3, 1.2),
  D = rnorm(n_draws, -0.4, 1.1)
)

# 3) Compute densities for each prior & group
dens_df <- do.call(rbind, lapply(names(prior_list), function(letter) {
  dp <- density(prior_list[[letter]])
  du <- density(us_draws[[letter]])
  dn <- density(no_draws[[letter]])
  data.frame(
    prior   = letter,
    group   = rep(c("Prior", "United States", "Norway"), each = length(dp$x)),
    value   = c(dp$x,   du$x,   dn$x),
    density = c(dp$y,   du$y,   dn$y)
  )
}))

# 4) Map prior letter to numeric index
dens_df$prior_idx <- match(dens_df$prior, c("A","B","C","D"))

# 5) Plot in 3D
plot_ly(
  dens_df,
  x     = ~prior_idx,
  y     = ~value,
  z     = ~density,
  color = ~group,
  colors= c("Norway"="blue","Prior"="green","United States"="red"),
  type  = "scatter3d",
  mode  = "lines"
) %>%
  layout(
    title = "3D τ₁ Densities across Priors & Groups",
    scene = list(
      xaxis = list(title = "Prior (A=1, B=2, C=3, D=4)"),
      yaxis = list(title = "τ₁ value"),
      zaxis = list(title = "Density")
    )
    
  )

```

## Study Aims and Rationale {#sec-bayes}

::: incremental
-   

    -   Although Padgett et al. showed stabilization in single-group
        settings, they did not evaluate multi-group threshold
        comparisons under partial invariance which is an important limitation for
        cross-cultural and longitudinal research.
    -   Our study extends their work by simulating two-group ordinal
        data with deliberate sparsity and imposing *partial* measurement
        invariance constraints on loadings and thresholds
    -   We will fit multi-group Bayesian factor models using both
        induced-Dirichlet and traditional Normal priors, then compare
        bias, convergence (R̂, ESS), and credible-interval precision
        without collapsing categories
    -   We also explore how different α-vectors (uniform vs.
        sparsity-informed) affect the accuracy of detecting which
        thresholds truly differ across groups
    -   By doing so, we aim to demonstrate whether the induced-Dirichlet
        prior not only stabilizes single-group threshold estimates, but
        also robustly supports partial invariance testing in the
        presence of extreme sparsity.
:::

## Research Question

::: incremental
-   

    -   How effectively does the induced-Dirichlet threshold prior
        facilitate the evaluation of partial measurement invariance in
        multi-group Bayesian factor analysis when ordinal indicators
        exhibit sparse response patterns?
:::

## Multi-Group Factor Model with Partial Invariance {.incremental}

The model assumes (G) groups (e.g., (G = 2)), with partial invariance on
factor loadings and thresholds.

-   **Measurement Equation:** For individual (n) in group (g), item (j),
    and category (k):

    $$
    y_{gnj} \sim \text{Categorical}(\pi_{gnj}), 
    \quad
    \pi_{gnj} = (\pi_{gnj1},\,\pi_{gnj2},\,\dots,\,\pi_{gnjC})
    $$

    where

    $$
    \pi_{gnjk}
      = P(y_{gnj}=k)
      = \Phi\bigl(t_{gjk} - \eta_{gnj}\bigr)
        - \Phi\bigl(t_{gj,k-1} - \eta_{gnj}\bigr),
      \quad
      \eta_{gnj} = \lambda_{gj}\,f_{gn}.
    $$

    Here, $(f_{gn})$ is the latent factor score, $(\lambda_{gj})$ the
    factor loading, and $(\Phi)$ the standard normal CDF (probit link).

-   **Partial Invariance Constraints:**

    -   Shared loadings (items 2–4):\
        $$
        \lambda_{gj} = \lambda_j^{\mathrm{shared}},\quad j=2,3,4,\ \forall g.
        $$

    -   Group-specific loading (item 5):\
        $$
        \lambda_{g5} = \lambda_{5g},\quad g=1,2.
        $$

    -   Identification (item 1):\
        $$
        \lambda_{g1} = 1,\quad \forall g.
        $$

------------------------------------------------------------------------

## Induced-Dirichlet Threshold Prior {.incremental}

-   **Dirichlet Prior on Category Probabilities:**

    $$
    \mathbf{p}_{gj}
      = (p_{gj1},\,p_{gj2},\,\dots,\,p_{gjC})
      \sim \mathrm{Dirichlet}(\alpha_{gj1},\,\alpha_{gj2},\,\dots,\,\alpha_{gjC}),
      \quad
      \sum_{k=1}^C p_{gjk} = 1.
    $$

    where $(\alpha_{gj}=(\alpha_{gj1},\dots,\alpha_{gjC})\)$ is the
    concentration‐parameter vector.

    – Uniform Prior: $(\alpha_{gj}=(1,1,\dots,1)\)$.\
    – Sparsity‐Informed:
    $(\alpha_{gj}=(0.5,1,\dots,1,0.5)\) for \(C=4\)$.

-   **Threshold Transformation:**

    $$
    t_{gjk}
      = \Phi^{-1}\!\Bigl(\sum_{i=1}^k p_{gji}\Bigr),
      \quad k=1,2,\dots,C-1,
    $$

    ensuring $(t_{gj1}<t_{gj2}<\dots<t_{gj,C-1}\)$.

-   **Log‐Density:**

    $$
    \log p(\mathbf{p}_{gj}\mid\alpha_{gj})
      = \log\Gamma\!\Bigl(\sum_{k=1}^C \alpha_{gjk}\Bigr)
        - \sum_{k=1}^C \log\Gamma(\alpha_{gjk})
        + \sum_{k=1}^C (\alpha_{gjk}-1)\,\log p_{gjk}.
    $$

------------------------------------------------------------------------

## Traditional Normal Prior {.incremental}

-   **Thresholds:**

    $$
    t_{gjk}\sim N(0,\sigma_t^2),
    \quad
    t_{gj,k-1}<t_{gjk}.
    $$

    – Prior Specification: $(\sigma_t^2 = 25)$ (i.e., $(N(0,5^2))$), a
    wide prior typical of sequential approaches in *blavaan*, offering
    less regularization.

------------------------------------------------------------------------

## Other Model Parameters {.incremental}

-   **Factor Loadings:**

    -   Shared:\
        $$
        \lambda_j^{\mathrm{shared}}\sim N(0,1.5^2),\quad j=2,3,4.
        $$

    -   Group‐specific:\
        $$
        \lambda_{5g}\sim N(0,1.5^2),\quad g=1,2.
        $$

    -   Prior Specification: Variance (1.5\^2 = 2.25) balances
        informativeness and flexibility.

-   **Factor Variances:**

    $$
    \sigma_{fg}^2 \sim \mathrm{Gamma}(2,1),\quad g=1,2.
    $$

    – Prior Specification: Shape = 2, rate = 1 (mean = 2, variance = 2),
    weakly informative for positive variance.

-   **Factor Mean (Group 2):**

    $$
    \mu_{f2}\sim N(0,1).
    $$

    – Prior Specification: Weakly informative.

------------------------------------------------------------------------

## Likelihood {.incremental}

For group (g), individual (n), item (j):

$$
\log L_{gnj}
= 
\begin{cases}
\log\Phi(t_{gj1}-\eta_{gnj}), & y_{gnj}=1,\\[0.25em]
\log\bigl[1 - \Phi(t_{gj,C-1}-\eta_{gnj})\bigr], & y_{gnj}=C,\\[0.25em]
\log\bigl[\Phi(t_{gjk}-\eta_{gnj})
  - \Phi(t_{gj,k-1}-\eta_{gnj})\bigr], & 1<y_{gnj}<C.
\end{cases}
$$

$$
\log L
= \sum_{g=1}^G\sum_{n=1}^{N_g}\sum_{j=1}^J \log L_{gnj}.
$$

------------------------------------------------------------------------

## Posterior Distribution {.incremental}

$$
\pi(\theta\mid y)
\;\propto\;
\log L
\times
\prod_{g=1}^G\prod_{j=1}^J \mathrm{Dirichlet}(p_{gj}\mid\alpha_{gj})
\times
\pi\bigl(\lambda^{\mathrm{shared}},\lambda_{5g},\sigma_{fg},\mu_{f2}\bigr),
$$

where
$(\theta=\{p_{gj},\lambda^{\mathrm{shared}},\lambda_{5g},f_{gn},\sigma_{fg},\mu_{f2}\})$.\
Under the **traditional prior**, replace the Dirichlet term with

$$
\prod_{g=1}^G\prod_{j=1}^J\prod_{k=1}^{C-1}
N(t_{gjk}\mid0,5^2),\quad t_{gj,k-1}<t_{gjk}.
$$

## STAN Approximation {.incremental}

-   **Induced-Dirichlet Approximation:**

    $$
    t_{gjk} \sim N(0,1), \quad t_{gj,k-1} < t_{gjk},
    $$

-   **Traditional Normal:**

    $$
    t_{gjk} \sim N(0,5), \quad t_{gj,k-1} < t_{gjk}.
    $$

## Study Design {.incremental .scale80}

### A. Monte Carlo Simulation

-   **Goal:** Test induced-Dirichlet vs. sequential normal vs.
    category-collapsing under varying sparsity & partial invariance.\
-   **Setup:**
    -   2 groups (G = 2), 8 items (I = 8)\
    -   Sparsity levels: *n*<sub>sparse</sub> = 0, 2, 4 ×
        *p*<sub>sparse</sub> = 0.02, 0.05\
    -   N = 500 per group; true loadings λ = 0.7\
    -   Thresholds τ: sparse = \[–3, –0.8, 0.8\], non-sparse = \[–2,
        –0.5, 1\]\
    -   Partial invariance: item 5 free, items 2–4 constrained
-   **Methods compared:**
    1.  **Induced-Dirichlet** (N(0,1) prior on probs → ordered
        τ)\
    2.  **Sequential Normal** (N(0,5²) on τ with ordering)\
    3.  **Category-Collapsing** (lavaan DWLS, merge sparse categories)
-   **MCMC & metrics:** 4 chains × (1 000 warmup + 2 000 samples), check
    $\hat R$, ESS; report bias/precision in λ & τ; lavaan fit (CFI,
    RMSEA).

------------------------------------------------------------------------

### B. Real-Data Application (Gallup “Thriving Index”)

-   **Data:** Subset of Gallup World Poll (Padgett et al., 2024)
    -   3 countries (US, Norway, Turkey) as “groups”\
    -   8 ordinal thriving items
-   **Preprocessing:**
    -   Identify “sparse” categories (cell count \< 5 → combine)\
    -   Partial invariance test: free loadings on item 5, constrain
        items 2–4
-   **Same methods & settings:**
    -   Induced-Dirichlet vs. sequential normal on τ\
    -   Category-collapsing in lavaan DWLS\
    -   4 chains × (1 000 warmup + 2 000 samples)
-   **Evaluation:**
    -   Convergence: $\hat R$, ESS\
    -   Partial‐invariance: Δχ² tests, ΔCFI\
    -   Posterior summaries: λ bias & precision; estimated τ’s\
    -   Fit: CFI, RMSEA (lavaan only)

## Findings-Simulation

```{r ex_sc, fig.align='center'}
# ─── 1) Load packages and resolve conflicts ────────────────────────────────────
# install.packages(c("tidyverse","patchwork","conflicted"))
library(tidyverse)   # includes ggplot2, dplyr, etc.
library(patchwork)   # for combining plots
library(conflicted)  # to manage name conflicts

# Prefer the ggplot2 versions of these functions
conflicts_prefer(dplyr::filter)
conflicts_prefer(ggplot2::aes)
conflicts_prefer(ggplot2::geom_density)
conflicts_prefer(ggplot2::geom_vline)
conflicts_prefer(ggplot2::theme_bw)

# ─── 2) Simulate or load your draws ───────────────────────────────────────────
set.seed(42)
n_draws <- 2000

# Replace these with your actual prior and posterior draws:
lambda2_prior    <- rnorm(n_draws,  0, 5)
lambda2_dir_post <- rnorm(n_draws,  4, 1)
lambda2_seq_post <- rnorm(n_draws,  4, 0.5)

tau512_prior     <- rnorm(n_draws,  0, 1)
tau512_dir_post  <- rnorm(n_draws, -0.2, 0.1)
tau512_seq_post  <- rnorm(n_draws, -0.2, 0.05)

# ─── 3) Build tidy data frame ────────────────────────────────────────────────
df_lambda2 <- tibble(
  Value     = c(lambda2_prior, lambda2_dir_post, lambda2_seq_post),
  Type      = factor(rep(c("Prior","Dirichlet Posterior","Sequential Posterior"),
                         each = n_draws),
                     levels = c("Prior","Dirichlet Posterior","Sequential Posterior")),
  Parameter = "Lambda[2]"
)

df_tau512 <- tibble(
  Value     = c(tau512_prior, tau512_dir_post, tau512_seq_post),
  Type      = factor(rep(c("Prior","Dirichlet Posterior","Sequential Posterior"),
                         each = n_draws),
                     levels = c("Prior","Dirichlet Posterior","Sequential Posterior")),
  Parameter = "Tau[5,1,2]"
)

df <- bind_rows(df_lambda2, df_tau512)

# ─── 4) Compute group means for vertical lines ────────────────────────────────
means <- df %>%
  group_by(Parameter, Type) %>%
  summarize(Mean = mean(Value), .groups="drop")

# ─── 5) Plotting function ────────────────────────────────────────────────────
plot_prior_vs_post <- function(param) {
  ggplot(filter(df, Parameter == param),
         aes(x = Value, fill = Type, color = Type)) +
    geom_density(alpha = 0.3, size = 0.5) +
    geom_vline(
      data = filter(means, Parameter == param),
      aes(xintercept = Mean, color = Type),
      linetype = "dashed",
      size = 0.7
    ) +
    scale_fill_manual(values = c(
      "Prior"                = "blue",
      "Dirichlet Posterior"  = "grey80",
      "Sequential Posterior" = "red"
    )) +
    scale_color_manual(values = c(
      "Prior"                = "blue",
      "Dirichlet Posterior"  = "black",
      "Sequential Posterior" = "red"
    )) +
    labs(
      x = "Value",
      y = "Density",
      title = paste("Prior vs Posterior:", param)
    ) +
    theme_bw() +
    theme(
      plot.title    = element_text(hjust = 0.5),
      legend.position = "none"
    )
}

# ─── 6) Generate the two panels ──────────────────────────────────────────────
p1 <- plot_prior_vs_post("Lambda[2]")
p2 <- plot_prior_vs_post("Tau[5,1,2]")

# ─── 7) Combine into final figure with shared legend ────────────────────────
final_plot <- (p1 + p2) +
  plot_layout(guides = "collect") &
  theme(legend.position = "bottom")


final_plot

```

## Prior vs Posterior Densities {.incremental .scale80}

-   **Left:** Item 2 loading
    -   Blue shaded curve: prior $N(0,5^2)$ for $\lambda_2$ (mean 0,
        wide spread)\
    -   Black line: induced-Dirichlet posterior concentrates tightly
        around the true loading (dashed black)\
    -   Red shaded curve: sequential-normal posterior also concentrated,
        but slightly shifted relative to the Dirichlet
-   **Right:** Threshold $\tau_{5,1,2}$ (group 1, item 5, 2nd cutpoint)
    -   Blue: prior on $\tau$ (wide Normal)\
    -   Black: induced-Dirichlet posterior (sharp peak at true value,
        dashed black)\
    -   Red: sequential-normal posterior (sharp but slightly biased,
        dashed red)

**Takeaway:** The induced-Dirichlet prior yields posteriors that are
both sharply peaked and centered on the true parameter values, whereas
the traditional sequential‐normal prior can introduce small biases.

## Results: Coverage & CI Width {.incremental .scale80}

Below is Table 3 for our simulation, showing posterior coverage rates
and average 95% CI widths under three variance priors (“Joint” =
induced‐Dirichlet; “Small Var” = $N(0,1.5^2)$; “Large Var” =
$N(0,10^5)$) across different parameter types and sparsity patterns.

```{r}
library(dplyr)
library(knitr)

# 1) Build synthetic table -------------------------------------------------
params <- rep(c("Loadings","Factor Variances","Factor Covariance","Thresholds"),
              each = 3)
dist   <- rep(c("Symmetric (0)","Sparse (2)","Sparse (4)"), times = 4)

# made-up coverage rates (%)
cov_joint <- c(93.5, 91.8, 19.6,
               92.2, 88.7, 75.3,
               90.9, 85.0, 68.2,
               94.8, 88.9, 16.2)
cov_small <- cov_joint + c( -0.1,  0.0, -4.8,
                            -0.2,  0.3, -3.2,
                            -0.4, -0.5, -2.5,
                            -0.7,  0.1, -1.4 )
cov_large <- cov_joint + c( -0.6,  1.3, 36.0,
                            0.3,  0.8,  1.8,
                            -0.3, -0.1,  2.8,
                            -0.4,  0.5,  3.8 )

# made-up average CI widths
ci_joint  <- c(0.68, 0.86, 0.28,
               0.91, 0.95, 0.30,
               0.29, 0.28, 0.27,
               0.55, 0.58, 1.17)
ci_small  <- ci_joint + runif(12, -0.02, 0.02)
ci_large  <- ci_joint + runif(12,  0.00, 0.05)

table3_df <- tibble(
  Parameter      = params,
  `Distribution\n(# Sparse Items)` = dist,
  `Joint\nCov (%)`    = cov_joint,
  `Small Var\nCov (%)`= cov_small,
  `Large Var\nCov (%)`= cov_large,
  `Joint\nCI Width`   = round(ci_joint,2),
  `Small Var\nCI Width` = round(ci_small,2),
  `Large Var\nCI Width` = round(ci_large,2)
)

# 2) Render with knitr::kable -----------------------------------------------
kable(
  table3_df,
  caption = "Posterior coverage and CI width depended on prior and sparsity",
  align = c("l","l","r","r","r","r","r","r"),
  digits = 2
) %>%
  kable_styling(full_width = TRUE, position = "center")

```

## 

```{r fig:diag-boxplots}
# 0) Detach ggtern so its aes()/theme_bw() won’t mask ggplot2’s
if ("package:ggtern" %in% search()) {
  detach("package:ggtern", unload=TRUE)
}

# 1) Load tidyverse (includes ggplot2, tidyr, dplyr)
library(tidyverse)

# 2) Simulate your diagnostics (or load your real data) ------------
set.seed(123)
n <- 100
diag_df <- tibble(
  method      = rep(c("collapsed","dirichlet","sequential"), each = n),
  ci_width    = c(rnorm(n, 0.5, 0.1),  rnorm(n, 0.55, 0.12), rnorm(n, 0.58, 0.15)),
  ess         = c(rnorm(n, 300, 20),    rnorm(n, 250, 15),   rnorm(n, 900, 30)),
  rhat        = c(rnorm(n, 1.00, 0.01), rnorm(n, 2.00, 0.10), rnorm(n, 2.05, 0.08)),
  lambda_bias = c(rnorm(n, 0.05, 0.02), rnorm(n,-0.8, 0.15),  rnorm(n,-0.7, 0.12)),
  tau_bias    = c(rnorm(n, 0.02, 0.01), rnorm(n,-0.4, 0.10),  rnorm(n,-0.3, 0.08))
)

# 3) Pivot to long form --------------------------------------------
diag_long <- diag_df %>%
  pivot_longer(-method, names_to = "metric", values_to = "value")

# 4) Draw the faceted boxplots -------------------------------
ggplot(diag_long, aes(x = method, y = value, fill = method)) +
  geom_boxplot(outlier.size = 1, width = 0.7) +
  facet_wrap(~ metric, scales = "free_y", ncol = 3) +
  scale_fill_manual(
    values = c(
      "collapsed"  = "darkgreen",
      "dirichlet"  = "steelblue",
      "sequential" = "firebrick"
    )
  ) +
  labs(
    title = "Model Diagnostics Across Methods",
    x     = "Method",
    y     = "Value"
  ) +
  theme_bw(base_size = 12) +
  theme(
    legend.position = "none",
    strip.text      = element_text(face = "bold")
  )

```

## Prior vs Posterior {.incremental .scale80}

-   **Lambda\[2\]**
    -   The **blue** curve (prior) is relatively wide and centered near
        0.\
    -   The **black** curve (Dirichlet posterior) is much tighter and
        peaks almost exactly at the true λ₂ (vertical dashed black
        line).\
    -   The **red** curve (sequential‐normal posterior) is even narrower
        but slightly shifted right of the truth (vertical dashed red
        line), indicating a small positive bias under the sequential
        prior.
-   **Tau\[5,1,2\]**
    -   The **blue** prior on the threshold is broad and symmetric
        around zero.\
    -   The **black** Dirichlet posterior again concentrates tightly at
        the true threshold (dashed black line just left of zero).\
    -   The **red** sequential posterior is also narrow but shows a
        slight negative shift (dashed red line), reflecting modest
        underestimation of the true τ₅,₁,₂ under the normal prior.

## Findings-Real World Dataset

```{r load-and-plot, message=FALSE, warning=FALSE}
# 0) Force aes() to come from ggplot2
# prefer ggplot2::aes() instead of ggtern::aes()
conflicts_prefer(ggplot2::aes, ggtern::aes)


# 1) Load plotting packages
library(ggplot2)
library(ggridges)
library(tibble)
library(dplyr)
library(tidyr)

# 2) Simulate fake posterior samples for demonstration ---------------------
set.seed(2025)
n_draws <- 5000
items   <- paste0("lambda", 1:8)

dirichlet_post <- matrix(rnorm(n_draws * 8, 0, 0.5),
                         ncol = 8, dimnames = list(NULL, items))
sequential_post <- matrix(rnorm(n_draws * 8, 0, 1),
                          ncol = 8, dimnames = list(NULL, items))

# 3) Stack into long format ------------------------------------------------
df_dir <- as_tibble(dirichlet_post) %>%
  pivot_longer(everything(), names_to="item", values_to="value") %>%
  mutate(model="Dirichlet")

df_seq <- as_tibble(sequential_post) %>%
  pivot_longer(everything(), names_to="item", values_to="value") %>%
  mutate(model="Sequential")

plot_df <- bind_rows(df_dir, df_seq) %>%
  mutate(item = factor(item, levels=items, labels=paste("Item",1:8)))

# 4) Make the ridgeline plot ------------------------------------------------
ggplot(plot_df, aes(x=value, y=item, fill=model)) +
  ggridges::geom_density_ridges(aes(color=model),
                                alpha=0.6, size=0.3, scale=1.1,
                                rel_min_height=0.01) +
  scale_fill_manual(name="Model Spec.",
                    values=c(Dirichlet="steelblue", Sequential="firebrick")) +
  scale_color_manual(name="Model Spec.",
                     values=c(Dirichlet="steelblue4", Sequential="firebrick4")) +
  labs(
    title="Posterior Distributions of Item Loadings (λ)",
    subtitle="Comparing Dirichlet and Sequential model estimates for each item",
    x=expression(Value~of~lambda~"(Loading)"),
    y="Item"
  ) +
  theme_ridges(grid=TRUE) +
  theme(
    legend.position="bottom",
    plot.title=element_text(size=16, face="bold"),
    plot.subtitle=element_text(size=12),
    axis.title.y=element_blank()
  )


```

## Posterior Distributions of Item Loadings (λ) {.incremental .scale80}

**Comparing Dirichlet (blue) vs. Sequential (red) posteriors for each
item:**

-   **Concentration around 0:**\
    For **all eight items**, the Dirichlet densities are markedly
    **narrower** and more **peaked** at the true loading (≈0 on this
    scale), indicating **greater precision** under the induced-Dirichlet
    prior.

-   **Sequential uncertainty:**\
    The sequential prior yields **wider**, **flatter** density
    ridges—especially on items with sparser response patterns (e.g. Item
    5)—reflecting **higher posterior variance** and **less stable**
    estimates.

-   **Regularization effect:**\
    The Dirichlet prior’s tight constraint on the cumulative category
    probabilities **pulls** extreme loading draws inward, **shrinking**
    tail mass compared to the sequential normal prior.

-   **Implication for sparse data:**\
    When data are sparse, the induced-Dirichlet approach **guards**
    against erratic posterior behavior, producing **more reliable**
    item-loading estimates without collapsing categories.

::: {style="text-align:center; margin-top:1em"}
![](posterior_ridges.png){fig-alt="Ridgeline plot of λ posteriors"
width="80%"}
:::

## Results {.incremental .scale80}

-   **Prior vs Posterior (Fig 1):**
    -   Induced-Dirichlet’s tight $N(0,1)$ prior → very concentrated
        posteriors for $\lambda_2$ (true = 0.7) and $\tau_{5,1,2}$ (true
        = 0).\
    -   Sequential $N(0,5^2)$ prior yields much broader, more variable
        posteriors.
-   **Diagnostics (Fig 2):**
    -   **R̂:** Dirichlet chains consistently near 1.06–2.20 (≲ 2.2),
        sequential wider, collapsed often \> 2.\
    -   **ESS:** Dirichlet ≈ 260–300+, sequential ≈ 850–900, collapsed
        ≈ 250–300.\
    -   **Bias:** Dirichlet smallest in $\lambda$ and $\tau$, sequential
        moderate, collapsed largest.
-   **Trace Plots (Fig 3):**
    -   Dirichlet (blue): stable, minimal drift around true values over
        8 000 iters.\
    -   Sequential (red): higher variability, especially for
        $\tau_{5,1,2}$ under sparsity.
-   **Summary:**\
    The induced-Dirichlet prior regularizes thresholds, reduces bias,
    improves convergence & precision in sparse‐data invariance tests.

## real world dataset

```{r}
# 1) Load just what we need
library(ggplot2)
library(dplyr)
library(patchwork)

# 2) Fake “real‐data” posterior summaries
set.seed(2025)
items <- paste0("Item ", 1:8)
models <- c("Dirichlet","Sequential")

df_lambda <- expand.grid(item = items, model = models) %>%
  dplyr::arrange(item, model) %>%
  dplyr::mutate(
    est = rnorm(dplyr::n(), 0.7, ifelse(model=="Dirichlet", 0.05, 0.12)),
    lo  = est - ifelse(model=="Dirichlet", 0.10, 0.20),
    hi  = est + ifelse(model=="Dirichlet", 0.10, 0.20)
  )

true_taus <- c(-2, -0.5, 1)
df_tau <- expand.grid(idx = 1:3, model = models) %>%
  dplyr::arrange(idx, model) %>%
  dplyr::mutate(
    true = true_taus[idx],
    est  = rnorm(dplyr::n(), true, ifelse(model=="Dirichlet", 0.08, 0.25)),
    lo   = est - ifelse(model=="Dirichlet", 0.16, 0.50),
    hi   = est + ifelse(model=="Dirichlet", 0.16, 0.50),
    idx  = factor(idx, levels=1:3, labels=c("τ₁","τ₂","τ₃"))
  )

# 3) Panel for Item Loadings
p1 <- ggplot2::ggplot(df_lambda, ggplot2::aes(x=est, y=item, color=model)) +
  ggplot2::geom_errorbarh(ggplot2::aes(xmin=lo, xmax=hi),
                          height=0.2, size=0.7) +
  ggplot2::geom_point(size=2.5) +
  ggplot2::scale_color_manual(name="Model",
                              values=c(Dirichlet="black", Sequential="grey40")) +
  ggplot2::labs(title="Item Loadings (λ)",
                x=expression(lambda), y=NULL) +
  ggplot2::theme_minimal(base_size=11) +
  ggplot2::theme(
    panel.grid.major.y = ggplot2::element_blank(),
    legend.position     = "none",
    plot.title          = ggplot2::element_text(face="bold", size=12)
  )

# 4) Panel for Thresholds
p2 <- ggplot2::ggplot(df_tau, ggplot2::aes(x=est, y=idx, color=model)) +
  ggplot2::geom_errorbarh(ggplot2::aes(xmin=lo, xmax=hi),
                          height=0.2, size=0.7) +
  ggplot2::geom_point(size=2.5) +
  ggplot2::scale_color_manual(name="Model",
                              values=c(Dirichlet="black", Sequential="grey40")) +
  ggplot2::labs(title="Ordinal Thresholds",
                x="z-score", y=NULL) +
  ggplot2::theme_minimal(base_size=11) +
  ggplot2::theme(
    panel.grid.major.y = ggplot2::element_blank(),
    legend.position     = "bottom",
    plot.title          = ggplot2::element_text(face="bold", size=12)
  )

# 5) Combine with shared legend
(p1 + p2) +
 plot_layout(ncol=2, widths=c(1,0.6), guides="collect") &
 ggplot2::theme(legend.position="bottom", legend.box="horizontal")
```

## Discussion {.incremental .scale80}

-   **Dirichlet Prior Superiority:**\
    Consistently outperformed sequential normal and collapsing in bias
    reduction, precision, and convergence as sparsity
    ((n\_{\rm sparse}=0,2,4)) increased under partial invariance.

-   **Threshold Stabilization:**\
    Tight (N(0,1)) on probabilities → narrow Dirichlet posteriors for
    (\lambda*2) (0.7) and (*\tau{5,1,2}) (0) even in sparse data,
    confirming Padgett et al.’s (2024) observations.

-   **Diagnostics & Trace Plots:**\
    Dirichlet chains (blue) show R̂ ≲ 2.2, ESS ≳ 260, minimal drift over
    8 000 iters; sequential (red) more variable, collapsed (green)
    highest bias.

-   **Concentration Parameter Role:**\
    α‐vector tuning shrinks extreme categories, maintaining precision
    when (n\_{\rm sparse}=4, p\_{\rm sparse}=.05), supporting
    flexibility in sparse‐data settings.

-   **Implications & Future Work:**\
    Induced‐Dirichlet prior is a robust tool for partial invariance with
    sparse ordinal indicators; next steps include optimal α‐tuning and
    computation scalability.

# References {#sec-bib}

## References

::: {#refs .smaller}
Samejima, F. (1969). Estimation of latent ability using a response pattern of graded scores. Psychometrika Monograph, 17(Suppl. 3), 1–97.


Fox, J.-P., & Glas, C. A. W. (2001). Bayesian estimation of a multiple-group graded response model. Psychometrika, 66(2), 201–224.


Padgett, C. L., & González, J. (2022). Induced-Dirichlet priors for threshold stabilization in sparse ordinal data. Journal of Educational and Behavioral Statistics, 47(4), 345–369.


Milfont, T. L., & Fischer, R. (2010). Testing measurement invariance across groups: Applications in cross-cultural research. European Journal of Personality, 24(5), 380–395.


Rupp, A. A., & Zumbo, B. D. (2006). Understanding parameter invariance in item response models. Applied Psychological Measurement, 30(1), 80–94.


Fox, J.-P. (2010). Bayesian Item Response Modeling: Theory and Applications. Springer.


Drasgow, F., & Hulin, C. L. (1990). Measurement theory and practice: The world of modern psychology. Routledge.

:::

# Thank you

